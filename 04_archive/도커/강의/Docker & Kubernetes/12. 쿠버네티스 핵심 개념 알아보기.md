---
tags:
  - 도커
강의명: "Docker & Kubernetes : 실전 가이드"
---
기
### 사용자가 직접 해야할 일 

- 클러스터 와 노드 인스턴스 ( Worker + Master ) 생성
=> 쿠버네티스는 최종 아키텍처를 정의하는 올인원 도구
- API Server 설정 , kubelet 및 services / software 설치
- 필요시 , cloud provider 추가 생성 ( Load Balancer , FileSystem)

=> EKS 가 이러한 불편한 점들 제거하는데 도움을 주긴 함

### 쿠버네티스가 하는 일
- Pods 생성 및 관리 ( scale 확장 & 재 생성 )
- 제공된 provider 들에 대한 설정 및 목표 적용 지원
=> 애플리케이션 구동 및 유지에만 관심을 가짐


- 결국 쿠버네티스는 실행되야 하는 원래 방식으로 컨테이너 및 그와 관련된 모든 것 실행 + 애플리케이션 실행되게 하기 위해 배포된 애플리케이션 관리 ( 애플리케이션이 필요한 인프라에는 관심 X )

( 클러스터 , 마스터 노드 , 워커 노드 구성 정의 + 모든 리소스 생성 예상 가능 )

### 요구 설정 & 설치 단계

- 클러스터 필요 ( 마스터 노드 존재 클러스터는 여러 머신에 분산되어 항상 구동되 실행 가능 )
	=> 해당 클러스터에서 실행되는 하나의 가상 인스턴스 필요
	=> 역시나 , 워커 노드도 하나 이상의 필요
( 각 노드마다 필수 software 들을 설치해줘야함. )

- Local 에는 kubectl 설치 ( kube control )
	=> deployment 생성 및 삭제 or 실행중인 delopyment 변경 같은 명령 클러스터에 보내는 도구
	( 마스터 노드에 포드 추가 생성 명령 등 )
	!= API 서버 , 마스터 노드

- 테스팅을 위한 , 더미 클러스터 설정용 minikue 설치
- 로컬 머신 에서 가상 머신 사용해 클러스터 생성
	=> 시뮬레이션 가능 ( 단일 노드 클러스터 생성 - 워커 & 마스터 노드가 하나 단일 가상 머신으로 결합 )

### kubectl
- k8s 클러스터 내 실행 중 작업 관리하기 위한 주요 명령줄 도구
- 원격으로 클러스터에 연결해 클러스터의 리소스 및 상태 관리


### MiniKube

- 로컬 환경에서 k8s 환경 설정을 체험할 수 있는 프로그램 ( 개발 및 디버그 용 or 개념 배우는데 사용 )
- 독립된 k8s 클러스터 구축 ( 로컬 가상 머신을 사용해 클러스터 제어 )
#### In Mac OS

``` cmd
brew install minikube
```
- minikube 설치


``` cmd
minikube start
```
- 새로운 로컬 클러스터 시작 명령어
- 로컬에서 클러스터 시작하고 필요한 구성 설정 

![](https://i.imgur.com/EeomQO7.png)
=> M2 Air 기준 start 명령어 이후 나오는 Command ( m1 , m2 는 같은 실리콘 계열이기에 저렇게 뜨는거 같음 )
( Default 로 사용하는 VM 은 Docker Desktop driver )

``` CMD
minikube status
```

![](https://i.imgur.com/1A3oH4n.png)
- minikube Cluster 의 현재 상태 확인

- type : Minikube Cluster 의 유형 - Control Plane 은 클러스터에서 마스터 노드 의미
- host : Minikube Cluster 의 Host ( VM or Container ) 의 실행 상태 - Running 은 실행 중 의미
- kubelet : Minikube Cluster 의 kubelet Service 실행 중인지 나타냄 ( 각 노드 Pod 상태 관리 + 클러스터와 상호 작용 )
- apiServer : Minikube Cluster 의 k8s API Server 가 실행 중인지 나타냄.
- kubeconfig : 클러스터 관리하는 데 사용되는 kubeconfig 파일 구성되었음을 나타냄.

``` CMD
minikube dashboard
```


![](https://i.imgur.com/GwA82oV.png)

- Minikube Cluster 의 대시 보드 염
- 클러스터 상태 및 리소스 시각적 모니터링 하고 관리하는데 사용

![](https://i.imgur.com/S3hIIUN.png)


## Object

### Pod Object ( 결국 Container 를 래핑 )
- 임시적 ( 교체 및 제거 되면 데이터 손실 - 버그가 아닌 의도된 디자인)
- 하나 또는 여러개의 Container 포함 ( 관념은 1 pod - 1 container )
- 모든 Pod 내 Container들은 자원 공유 ( e.x : volumes )
- Cluster 내부 IP 소유 ( localhost 를 통해 통신 가능 )

### Deployment Object
- 수동으로 Pod 객체 직접 생성해서 특정 워커 노드는 말도 안되는 일 ( k8s 를 쓸 이유가 없어짐 )
- 생성 및 관리 할 pod 의 수와 컨테이너 수에 대한 지침 제공 ( 원하는 목표 상태를 설정하는 것 )
- deployment 일시 수정 및 삭제 및 롤백 용이
- Deployment 역시 , 동적 scale 가능 ( 또는 메트릭 설정에 기반한 오토 스케일링 )

#### Command ( 명령형 접근 )
``` CMD
kubectl create deployment --image=<Image경로>
```
- 주의해야할 점은 image 는 당연히 docker hub 에 push 되어 있는 경로

```cmd
kubectl get deployments
```
- 현재 있는 deployments 출력

```CMD
kubectl get pods
```
- 현재 존재하는 pods 출력

```cmd
kubectl delete deployment <deployments명>
```
- deployment 삭제
( 추가로 , 해당 deployment 를 통해 생성된 pods 도 전부 삭제 )

```terminal
NAME        READY   UP-TO-DATE   AVAILABLE   AGE

first-app   1/1     1            1           10m
```
- get deployments 시 나오는 결과

```terminal
NAME                        READY   STATUS    RESTARTS   AGE

first-app-78f6889fd-92x8k   1/1     Running   0          11m
```
- get pods 시 나오는 결과

![](https://i.imgur.com/HWSdQ0B.png)
- minikube dashboard 로 킬시 나오는 결과

![](https://i.imgur.com/25H5jEk.png)
- pod 클릭해서 들어갈 시 나오는 화면


#### kubectl 원리
kubectl create deployment --image 명령어시?
	=> 마스터 노드 로 전송
	=> 마스터 노드가 클러스터에 필요한 모든 것 생성 ( 워커 노드에 pod 배포 일 담당 )
	=> 실행 중 pod 분석해 새로 생성된 pod 가 가장 적합한 Node 찾음.
	=> 새로 생성된 pod 가 워커 노드 중 하나로 보내짐
	=> pod 모니러팅 하며 상태 확인
	

### Service 객체
##### 내부 IP 의 문제점?
1. 클러스터 외부에서는 pod 에 액세스 하는데 사용 불가능
2. pod 가 교체될 때마다 변경 된다는 것
=> 스케일링 시 매우 빈번히 발생
- IP 주소는 사실 pod 랑 통신하기에 훌룡한 도구는 아님.

Service 는 pod 를 그룹화 하고 , 공유 주소 및 공유 IP 제공
( 주소가 변경되지 않는 점 기대 가능 )
- service 를 통해 , 여러 pod 를 해당 service 에 포함 시켜 , 변경할 수 없는 IP 주소에 연결
- 클러스터 외부에서도 변경되지 않는 주소 노출하도록 service 단에서 가능

```cmd
kubectl expose deployment <deployment명> --type=<type명> --port=<port명>
```
##### ClusterIP
- 디폴트 타입
- 클러스터 내부에서만 연결 가능
##### NodePort
- 해당 deplomyment 가 실행 중인 워커 노드 IP 주소 통해 노출

##### LoadBalancer
- 인프라에 존재해야 하는 LoadBalancer 활용
- 실제로 이 service 대한 고유 주소 생성
- 트래픽을 이 service 일부 모든 pod 들에게 고르게 분산
- 클러스터 와 클러스터 실행 인프라가 지원하는 경우에만 사용 가능 ( AWS , minikube 등 )


```cmd
dragonsu@iyeongsuui-MacBookAir kub-action-01-starting-setup % kubectl expose deployment first-app --type=LoadBalancer --port=8080

service/first-app exposed

dragonsu@iyeongsuui-MacBookAir kub-action-01-starting-setup % kubectl get service

NAME         TYPE           CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE

first-app    LoadBalancer   10.96.118.8   <pending>     8080:30216/TCP   10s

kubernetes   ClusterIP      10.96.0.1     <none>        443/TCP          7h46m
```
- minikube 로 배포하여서 external-ip ( 외부 ip ) 는 pending 으로 뜸
=> minikube service <deployment 명> ( Local IP 로 Mapping 하여 노출) - 당연히 다른 provider 일 시 , 할 필요도 X 

### Scaling
```cmd
kubectl scale deployment/third-app --replicas=3
```

```cmd
kubectl get pods

NAME                          READY   STATUS    RESTARTS   AGE

third-app-8b97d6999-dg7pt     1/1     Running   0          6s

third-app-8b97d6999-l5r87     1/1     Running   0          5m52s

third-app-8b97d6999-tffrt     1/1     Running   0          6s
```
- 해당 결과로 pods 가 3개로 증가 ( 기존  1 + 새로운 2 )
- 로드 밸런서가 있으니 트래픽도 고르게 분산
=> 하나가 에러 나도 , 정상 작동 ( 다른 pod 로 트래픽이 가므로 )
=> 에러 후 자동 복구

### Deployment 갱신

```cmd
kubectl set image deployment/<deployment명> <현재 적용중인 service명>=<적용할 service명>
```
- 적용중인 service 명을 모르겠으면 dashboard 들어가서 확인
- 이때 주의해야할 점은 기존과 동일한 tag 로 수행하면 되지 않는다!

- 완료시 나오는 출력
=> deployment.apps/third-app image updated

```cmd
kubectl rollout status deployment/<depolyment명>
```
- 배포 리소스의 배포 상태 확인

#### Rollback
- 잘못된 Image 를 넣었을 경우?
- 위 kubectl rollout status 명령어로 확인할 시 ,
	=>Waiting for deployment "third-app" rollout to finish: 1 old replicas are pending termination...

- Pod 상태 조회시?
=>  ImagePullBackOff 상태
- 이렇게 Pod 오류시 , 전체 오류가 아닌 새로운 Pod 를 구동 중 오류 발생으로 , 기존 Pod 는 정상 작동 중임!
	( 매우 편리한 장점 - deploy 실패시에도 , 예전께 그대로 정상 작동 중임 )

```cmd
kubectl rollout undo deployment/<deployment명>
kubectl rollout undo deployment/<deployment명> --to-revision=<revision 번호>
```
- --to-revision 명령어 없을시? : 최근 deployment 를 undo 
- 해당 deployment 를 통해 발생한 문제 있는 Pod 도 같이 제거


```cmd
kubectl rollout history deployment/<deplyment명>
kubectl rollout history deployment/<deployment명> --revision=<revision 번호>
```
=> 첫번째 Command 결과 ( 하단 )
```cmd
REVISION  CHANGE-CAUSE

1         <none>
3         <none>
4         <none>
```
=> 두번째 Command 결과 ( 하단 )
```
deployment.apps/third-app with revision #3
Pod Template:
  Labels: app=third-app
pod-template-hash=5c4d648cd
  Containers:
   kub-first-app:
    Image: youngsu5582/kub-first-app:3
    Port: <none>
    Host Port: <none>
    Environment: <none>
    Mounts: <none>
  Volumes: <none>
```




### 명령적 vs 선언적
#### Imperative
- kubectl creat deployment <> ... 느낌으로 생성
- 독립적인 commnad 가 특정 action 수행
- docker run 과 유사함 ( 하나하나씩 직접 실행 )

#### Declarative
- kubectl apply -f config.yaml 느낌으로 실행
- file 을 선언하고 , aplly 시 변경 사항 살펴보고 반영
- docker-compose 와 유사함 ( 파일에 구성하고 적용 )




## 선언적
- 참고 사이트 : https://kubernetes.io/docs/concepts/overview/working-with-objects/

### Deployment yaml
``` yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 2
  selector:
    matchLabels:
      app: second-app
      tier: backend
    matchExpressions:
	    - {key:app,operation:In,values[second-app,first-app]}
  template:
    metadata:
      labels:
        app: second-app
        tier: backend
    spec:
      containers:
        - name: second-node
          image: youngsu5582/kub-first-app:2
          livenessProbe:
	          httpGet:
		          path: /
		          port: 8080
```
- apiVersion 은 k8s yml 임을 알려줌
- kind 는 배포할 종류 지정 ( Deployment , Service 등 지정 )
- metadata 는 name 과 labels 지정 가능
- spec 은 리소스 구체적인 구성 정의
##### spec
- replicas 는 복제할 개수 지정
- selector 는 deployment 가 계속적으로 관리하기 위해 , 관리할 pod 를 선택하기 위해 선언 ( matchLabels , matchPatterns 존재 )
	뒤에 key-value 형식으로 , 관리해야 할 조건 나열 ( app 이 second-app 이고 , tier 가 backend 인 pod 만 선택 )
- template 로 Pod 생성에 활용할 템플릿 정의
	- metadata 로 Pod 의 label 지정
	- spec 의 containers 에 이름 및 사용 이미지 지정
##### livenessProbe
-  '/' 해당 경로 8080 port 로 , GET 요청을 보냈는데 , 오지 않을시 문제로 판단하고 , 정상 상태 유지 시도

### Service yaml
```yaml
apiVersion: v1
kind: Service
metadata:
	name: backend
spec:
	selector:
		app:second-app
	ports:
		- protocol: 'TCP'
		  port: 80
		  targetPort: 8080
	type: LoadBalancer
```
- Service 지정
- metadata 로 상세 지정
##### spec
- select 는 위와 동일
- ports 로 지정 ( protocl 지정 , 외부로 노출할 port , target 으로 잡는 내부 targetPort )

```cmd
kubectl delete -f=<file명>
kubectl delete deployments,services -l <key>=<value>
```
=> 해당 yaml 을 통해 생성된 resource 들을 삭제
- -f 옵션은 여러개 지정 가능 
- -l 옵션으로 해당 key 와 value 를 만족하는 labels 만 제거

#### 다중 config 를 -> 단일 config 에 합치기
모든 내용 밑에 --- 세 개의 대시 추가

 apiVerison ~~
 ---
 apiVersion~~
	